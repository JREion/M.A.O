# MAO: Efficient Model-Agnostic Optimization of Prompt Tuning for Vision-Language Models 


> **[ICME 2025] MAO: Efficient Model-Agnostic Optimization of Prompt Tuning for Vision-Language Models** <br>
> Haoyang Li, Siyu Zhou, Liang Wang and Guodong Long. <br>
> Shanghai University, University of Technology Sydney <br>

<hr />

### ðŸ”¥ News

- **NOTE**: We are preparing our code repository (mainly rewriting comments to improve readability). We hope to release code in April.

- (21 Mar. 2025) Our paper is accepted by ICME 2025!


## Acknowledgements

#### ðŸ§° Repositories
Our code is based on [DPC](https://github.com/JREion/DPC), [DePT](https://github.com/Koorye/DePT), [PromptSRC](https://github.com/muzairkhattak/PromptSRC), [MaPLe](https://github.com/muzairkhattak/multimodal-prompt-learning) and [CoOp](https://github.com/KaiyangZhou/CoOp) repository. We thank the authors for releasing their code.

#### ðŸ’– Special Thanks
_The author extends heartfelt gratitude to the two M.A.O. â€” to him and to her â€” whose presence has enriched the soul and bestowed the strength to journey forward._
